---
name: multimodel
name_long: Basic simulation for every possible combination of selected models

scripts:
  - data_describe.py
  - get_plot.py
  - merge_descriptives.py
  - merge_metrics.py
  - merge_tds.py

docs:
  - README.md
---

{# This is a template for the multimodel method #}
# version {{ version }}

# Create folder structure. By default, the folder 'output' is used to store output.
mkdir {{ output_folder }}
mkdir {{ output_folder }}/simulation
mkdir {{ output_folder }}/tables
mkdir {{ output_folder }}/tables/metrics
mkdir {{ output_folder }}/tables/time_to_discovery
mkdir {{ output_folder }}/figures
{% for dataset in datasets %}

##################################
### DATASET: {{ dataset.input_file_stem }}
##################################

# Create output folder
mkdir {{ output_folder }}/simulation/{{ dataset.input_file_stem }}/
mkdir {{ output_folder }}/simulation/{{ dataset.input_file_stem }}/metrics

# Collect descriptives about the dataset {{ dataset.input_file_stem }}
mkdir {{ output_folder }}/simulation/{{ dataset.input_file_stem }}/descriptives
python {{ scripts_folder }}/data_describe.py {{ dataset.input_file }} -o {{ output_folder }}/simulation/{{ dataset.input_file_stem }}/descriptives/data_stats_{{ dataset.input_file_stem }}.json

# Simulate runs
mkdir {{ output_folder }}/simulation/{{ dataset.input_file_stem }}/state_files
{% for classifier in all_classifiers %}
{% for feature_extraction in all_feature_extractors %}
{% for querier in all_queriers %}
{% for balancer in all_balancers %}
{% set temp = [] %}{{ temp.append(classifier)|default("", True) }}{{ temp.append(feature_extraction)|default("", True) }}
{% if temp in impossible_models %}

# Skipped {{ classifier }} + {{ feature_extraction }} + {{ querier}} model
{% else %}# Classifier = {{ classifier }}, Feature extractor = {{ feature_extraction }}, Query strategy = {{ querier }}, Balance strategy = {{balancer}}
{% for run in range(n_runs) %}
python -m asreview simulate {{ dataset.input_file }} -o {{ output_folder }}/simulation/{{ dataset.input_file_stem }}/state_files/sim_{{ dataset.input_file_stem }}_{{ classifier }}_{{ feature_extraction }}_{{ querier }}_{{ balancer }}{{ "_{}".format(run) if n_runs > 1 else "" }}.asreview -c {{ classifier }} -q {{querier}} -e {{ feature_extraction }} -b {{ balancer }}  --prior-seed {{ dataset.prior_seed + run }} --seed {{ dataset.model_seed }} --n-query {{ n_query }}{% if n_stop %} --n-stop {{ n_stop }}{% endif %}

python -m asreview metrics {{ output_folder }}/simulation/{{ dataset.input_file_stem }}/state_files/sim_{{ dataset.input_file_stem }}_{{ classifier }}_{{ feature_extraction }}_{{ querier }}_{{ balancer }}{{ "_{}".format(run) if n_runs > 1 else "" }}.asreview -o {{ output_folder }}/simulation/{{ dataset.input_file_stem }}/metrics/metrics_sim_{{ dataset.input_file_stem }}_{{ classifier }}_{{ feature_extraction }}_{{ querier }}_{{ balancer }}{{ "_{}".format(run) if n_runs > 1 else "" }}.json --quiet
{% endfor %}{% endif %}
{% endfor %}
{% endfor %}
{% endfor %}
{% endfor %}

# Generate plot and tables for dataset
python {{ scripts_folder }}/get_plot.py -s {{ output_folder }}/simulation/{{ dataset.input_file_stem }}/state_files/ -o {{ output_folder }}/figures/plot_recall_sim_{{ dataset.input_file_stem }}.png --show-legend model
python {{ scripts_folder }}/merge_metrics.py -s {{ output_folder }}/simulation/{{ dataset.input_file_stem }}/metrics/ -o {{ output_folder }}/tables/metrics/metrics_sim_{{ dataset.input_file_stem }}.csv
python {{ scripts_folder }}/merge_tds.py -s {{ output_folder }}/simulation/{{ dataset.input_file_stem }}/metrics/ -o {{ output_folder }}/tables/time_to_discovery/tds_sim_{{ dataset.input_file_stem }}.csv
{% endfor %}

# Merge descriptives and metrics
python {{ scripts_folder }}/merge_descriptives.py
python {{ scripts_folder }}/merge_metrics.py
